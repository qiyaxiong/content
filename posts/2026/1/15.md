---
title: agent中skills
published: 2026-01-15
tags: [skills]
category: Agent
draft: false
---
### langchain中skills的处理

对于一个agent来说,tools代表这这个agent可以去做什么,例如;读写文件,调用http请求

但是对于skills来说,就是告诉agent来怎么去做,我认为就是一个子人设,整个prompt的内容就这么多,但是我们还是希望他可以做一些其他的事情,但是我们又不想用去使用多agent来增加复杂度,可以使用skils来做,当触发到某些设定时,他会加载对应的skills来加载人设来进行回复,并且可以绑定特定合适工具来进行精准的回复

### 为什么使用skills

#### 渐进式披露

Layer 1: 元数据 (始终加载)     ~100 tokens/skill
         └─ name + description

Layer 2: SKILL.md 主体 (触发时)   ~2000 tokens
         └─ 详细指南

Layer 3: 资源文件 (按需)        无限制
         └─ scripts/, references/, assets/

他只是加载头部摘要描述,name + description,只需要讲清楚需要他的做什么的,当需要他的时候他才会把完整的内容加载进去

#### SKILL.md 标准

skills/
├── pdf/
│   └── SKILL.md          # 必需

**SKILL.md 格式** ：YAML 前置 + Markdown 正文

```
---
name: pdf
description: 处理 PDF 文件。用于读取、创建或合并 PDF。
---
```

#### 自回归模型与 KV Cache

> 每次生成token都要attend之前的所有token,导致计算量非常大,为了避免重复计算,使用kv缓存

请求 1: [System, User1, Asst1, User2]
        ←────── 全部计算 ──────→

请求 2: [System, User1, Asst1, User2, Asst2, User3]
        ←────── 缓存命中 ──────→ ←─ 新计算 ─→
               (更便宜)            (正常价格)

但是这个的前提是前缀相同

| 操作               | 影响         | 结果               |
| ------------------ | ------------ | ------------------ |
| 编辑历史           | 改变前缀     | 缓存无法复用       |
| 中间插入           | 后续前缀变化 | 需要重新计算       |
| 修改 system prompt | 最前面变化   | 整个前缀需重新计算 |

这样的话可以保证提示词不变,但是外部获取的文档可以随时变化,下面我们来看在langchain中是怎么实现的

### 如何实现

#### 数据结构

```python
class SkillMetadata(TypedDict):
    name: str          # skill 名称  
    description: str   # 一句话描述  
from typing import TypedDict

class Skill(TypedDict):  
    """A skill that can be progressively disclosed to the agent."""
    name: str  # Unique identifier for the skill
    description: str  # 1-2 sentence description to show in system prompt
    content: str  # Full skill content with detailed instructions
```

#### 创建技能加载工具

```python
from langchain.tools import tool

@tool
def load_skill(skill_name: str) -> str:
    """Load the full content of a skill into the agent's context.

    Use this when you need detailed information about how to handle a specific
    type of request. This will provide you with comprehensive instructions,
    policies, and guidelines for the skill area.

    Args:
        skill_name: The name of the skill to load (e.g., "expense_reporting", "travel_booking")
    """
    # Find and return the requested skill
    for skill in SKILLS:
        if skill["name"] == skill_name:
            return f"Loaded skill: {skill_name}\n\n{skill['content']}"

    # Skill not found
    available = ", ".join(s["name"] for s in SKILLS)
    return f"Skill '{skill_name}' not found. Available skills: {available}"
```

#### 构建中间键

```python
from langchain.agents.middleware import ModelRequest, ModelResponse, AgentMiddleware
from langchain.messages import SystemMessage
from typing import Callable

class SkillMiddleware(AgentMiddleware):  
    """Middleware that injects skill descriptions into the system prompt."""

    # Register the load_skill tool as a class variable
    tools = [load_skill]  

    def __init__(self):
        """Initialize and generate the skills prompt from SKILLS."""
        # Build skills prompt from the SKILLS list
        skills_list = []
        for skill in SKILLS:
            skills_list.append(
                f"- **{skill['name']}**: {skill['description']}"
            )
        self.skills_prompt = "\n".join(skills_list)

    def wrap_model_call(
        self,
        request: ModelRequest,
        handler: Callable[[ModelRequest], ModelResponse],
    ) -> ModelResponse:
        """Sync: Inject skill descriptions into system prompt."""
        # Build the skills addendum
        skills_addendum = ( 
            f"\n\n## Available Skills\n\n{self.skills_prompt}\n\n"
            "Use the load_skill tool when you need detailed information "
            "about handling a specific type of request."
        )

        # Append to system message content blocks
        new_content = list(request.system_message.content_blocks) + [
            {"type": "text", "text": skills_addendum}
        ]
        new_system_message = SystemMessage(content=new_content)
        modified_request = request.override(system_message=new_system_message)
        return handler(modified_request)
```

#### 测试渐进披露

```python
import uuid

# Configuration for this conversation thread
thread_id = str(uuid.uuid4())
config = {"configurable": {"thread_id": thread_id}}

# Ask for a SQL query
result = agent.invoke(  
    {
        "messages": [
            {
                "role": "user",
                "content": (
                    "Write a SQL query to find all customers "
                    "who made orders over $1000 in the last month"
                ),
            }
        ]
    },
    config
)

# Print the conversation
for message in result["messages"]:
    if hasattr(message, 'pretty_print'):
        message.pretty_print()
    else:
        print(f"{message.type}: {message.content}")
```
